{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Key ideas in ProGAN\n",
    "\n",
    "# - Progressive growing of the resolution\n",
    "# - Minibatch standardization\n",
    "# - Pixel Norm\n",
    "# - Equalized learning rate\n",
    "\n",
    "# Architecture\n",
    "\n",
    "# - both the descriminator and the generator are mirror images of each other\n",
    "# - much faster traiing time\n",
    "# - use minibatch standardization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.datasets as datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torch.utils.data import DataLoader\n",
    "from math import log2, sqrt\n",
    "import torchvision\n",
    "import numpy as np\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "from torchvision.utils import save_image\n",
    "from scipy.stats import truncnorm\n",
    "from tqdm import tqdm\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Run name: stormy-indigo\n"
     ]
    }
   ],
   "source": [
    "WEATHER_CONDITIONS = [\n",
    "    'sunny', 'cloudy', 'rainy', 'snowy', 'windy', 'stormy', 'foggy', 'hail', \n",
    "    'thunderstorm', 'tornado', 'hurricane', 'blizzard', 'drizzle', 'sleet', \n",
    "    'dust storm'\n",
    "]\n",
    "COLOURS = [\n",
    "    'red', 'blue', 'green', 'yellow', 'purple', 'orange', 'black', 'white', \n",
    "    'pink', 'brown', 'grey', 'violet', 'indigo', 'turquoise', 'gold'\n",
    "]\n",
    "\n",
    "RUN_NAME = f'{WEATHER_CONDITIONS[np.random.randint(0,14)]}-{COLOURS[np.random.randint(0,14)]}'\n",
    "\n",
    "print(f'Run name: {RUN_NAME}')\n",
    "\n",
    "if not os.path.exists('../runs/ProGAN/checkpoints'):\n",
    "    print('Creating Checkpoint Directory')\n",
    "    os.makedirs('../runs/ProGAN/checkpoints')\n",
    "\n",
    "os.makedirs(f'../data/runs/ProGAN/{RUN_NAME}/log', exist_ok=True)\n",
    "os.makedirs(f'../data/runs/ProGAN/{RUN_NAME}/fake', exist_ok=True)\n",
    "os.makedirs(f'../data/runs/ProGAN/{RUN_NAME}/real', exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model\n",
    "\n",
    "factors = [1, 1, 1, 1, 1 / 2, 1 / 4, 1 / 8, 1 / 16, 1 / 32]\n",
    "\n",
    "\n",
    "class WSConv2d(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=1, padding=1,gain=2):\n",
    "        super(WSConv2d, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "        self.scale = (gain / (in_channels + kernel_size ** 2)) ** 0.5\n",
    "        self.bias = self.conv.bias\n",
    "        self.conv.bias = None\n",
    "\n",
    "        nn.init.normal_(self.conv.weight)\n",
    "        nn.init.zeros_(self.bias)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.conv(x * self.scale) + self.bias.view(1, self.bias.shape[0],1,1)\n",
    "\n",
    "\n",
    "class PixelNorm(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(PixelNorm, self).__init__()\n",
    "        self.epsilon = 1e-8\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * torch.sqrt(torch.mean(x ** 2, dim=1, keepdim=True) + self.epsilon)\n",
    "    \n",
    "\n",
    "class ConvBlock(nn.Module):\n",
    "    def __init__(self,in_channels,out_channels,use_pixel_norm=True):\n",
    "        super(ConvBlock, self).__init__()\n",
    "        self.conv1 = WSConv2d(in_channels,out_channels)\n",
    "        self.conv2 = WSConv2d(out_channels,out_channels)\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "        self.pn = PixelNorm()\n",
    "        self.use_pixel_norm = use_pixel_norm\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.leaky(self.conv1(x))\n",
    "        x = self.pn(x) if self.use_pixel_norm else x\n",
    "        x = self.leaky(self.conv2(x))\n",
    "        x = self.pn(x) if self.use_pixel_norm else x\n",
    "        return x\n",
    "    \n",
    "\n",
    "class Generator(nn.Module):\n",
    "    def __init__(self, z_dim,in_channels,img_channels=3):\n",
    "        super(Generator, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            PixelNorm(),\n",
    "            nn.ConvTranspose2d(z_dim, in_channels, 4, 1, 0), # 1 x 1 -> 4 x 4\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, 3, 1, 1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            PixelNorm()\n",
    "        )\n",
    "        self.initial_rgb = WSConv2d(in_channels, img_channels, kernel_size=1, stride=1,padding=0)\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList(), nn.ModuleList([self.initial_rgb])\n",
    "\n",
    "        for i in range(len(factors) - 1):\n",
    "            # factors[i] = factors[i] + 1\n",
    "            conv_in_c = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i + 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c))\n",
    "            self.rgb_layers.append(WSConv2d(conv_out_c, img_channels, kernel_size=1, stride=1,padding=0))\n",
    "            \n",
    "\n",
    "    def fade_in(self, alpha, upscaled, generated):\n",
    "        return torch.tanh(alpha * generated + (1 - alpha) * upscaled)\n",
    "\n",
    "    def forward(self, z, alpha, steps):\n",
    "        out = self.initial(z)\n",
    "\n",
    "        if steps == 0:\n",
    "            return self.initial_rgb(out)\n",
    "        \n",
    "        for step in range(steps):\n",
    "            upscaled = F.interpolate(out, scale_factor=2, mode='nearest')\n",
    "            out = self.prog_blocks[step](upscaled)\n",
    "\n",
    "        final_upscaled = self.rgb_layers[steps - 1](upscaled)\n",
    "        final_out = self.rgb_layers[steps](out) # <-- potential bug note: look here if steps is correct\n",
    "\n",
    "\n",
    "        return self.fade_in(alpha, final_upscaled, final_out)\n",
    "\n",
    "\n",
    "\n",
    "class Discriminator(nn.Module):\n",
    "    def __init__(self,in_channels,img_channels=3):\n",
    "        super(Discriminator, self).__init__()\n",
    "        self.prog_blocks, self.rgb_layers = nn.ModuleList(), nn.ModuleList()\n",
    "        self.leaky = nn.LeakyReLU(0.2)\n",
    "\n",
    "        for i in range(len(factors) - 1,0,-1):\n",
    "            conv_in_c = int(in_channels * factors[i])\n",
    "            conv_out_c = int(in_channels * factors[i - 1])\n",
    "            self.prog_blocks.append(ConvBlock(conv_in_c, conv_out_c,use_pixel_norm=False))\n",
    "            self.rgb_layers.append(WSConv2d(img_channels, conv_in_c, kernel_size=1, stride=1, padding=0))\n",
    "\n",
    "\n",
    "        self.initial_rgb = WSConv2d(img_channels, in_channels, kernel_size=1, stride=1,padding=0) # potential bug note: look here if steps is correct\n",
    "        self.rgb_layers.append(self.initial_rgb)\n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2,stride=2)\n",
    "\n",
    "        # Block for 4 x 4 resolution\n",
    "        self.final_block = nn.Sequential(\n",
    "            WSConv2d(in_channels+1, in_channels, kernel_size=3, stride=1, padding=1),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, in_channels, kernel_size=4, stride=1, padding=0),\n",
    "            nn.LeakyReLU(0.2),\n",
    "            WSConv2d(in_channels, 1, kernel_size=1, stride=1 , padding=0)\n",
    "        )\n",
    "\n",
    "    def fade_in(self, alpha, downscaled, out):\n",
    "        return alpha * out + (1 - alpha) * downscaled\n",
    "    \n",
    "    def minibatch_std(self, x):\n",
    "        batch_stats = torch.std(x,dim=0).mean().repeat(x.shape[0],1,x.shape[2],x.shape[3])\n",
    "        return torch.cat([x,batch_stats],dim=1)\n",
    "\n",
    "    def forward(self, x, alpha, steps):\n",
    "        cur_step = len(self.prog_blocks) - steps\n",
    "        out = self.leaky(self.rgb_layers[cur_step](x))\n",
    "\n",
    "        if steps == 0:\n",
    "            out = self.minibatch_std(out)\n",
    "            return self.final_block(out).view(out.shape[0],-1)\n",
    "            \n",
    "        downscaled = self.leaky(self.rgb_layers[cur_step + 1](self.avg_pool(x)))\n",
    "        out = self.avg_pool(self.prog_blocks[cur_step](out))\n",
    "        out = self.fade_in(alpha, downscaled, out)\n",
    "\n",
    "        for step in range(cur_step + 1,len(self.prog_blocks)):\n",
    "            out = self.prog_blocks[step](out)\n",
    "            out = self.avg_pool(out)\n",
    "\n",
    "        out = self.minibatch_std(out)\n",
    "        return self.final_block(out).view(out.shape[0],-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generator Roger Roger at image size: 4\n",
      "Discriminator Roger Roger at image size: 4\n",
      "Generator Roger Roger at image size: 8\n",
      "Discriminator Roger Roger at image size: 8\n",
      "Generator Roger Roger at image size: 16\n",
      "Discriminator Roger Roger at image size: 16\n",
      "Generator Roger Roger at image size: 32\n",
      "Discriminator Roger Roger at image size: 32\n",
      "Generator Roger Roger at image size: 64\n",
      "Discriminator Roger Roger at image size: 64\n",
      "Generator Roger Roger at image size: 128\n",
      "Discriminator Roger Roger at image size: 128\n",
      "Generator Roger Roger at image size: 256\n",
      "Discriminator Roger Roger at image size: 256\n"
     ]
    }
   ],
   "source": [
    "# Testing the Forward Pass of the model\n",
    "\n",
    "testing = True\n",
    "\n",
    "if testing:\n",
    "    Z_DIM = 50\n",
    "    IN_CHANNELS = 256\n",
    "    gen = Generator(Z_DIM, IN_CHANNELS,img_channels=3)\n",
    "    critic = Discriminator(IN_CHANNELS, img_channels=3)\n",
    "\n",
    "    for img_size in [4,8,16,32,64,128,256]:\n",
    "        num_steps = int(log2(img_size / 4))\n",
    "        x = torch.randn(1, Z_DIM, 1, 1)\n",
    "        z = gen(x, 0.5, steps=num_steps)\n",
    "\n",
    "        assert z.shape == (1, 3, img_size, img_size)\n",
    "        print(f'Generator Roger Roger at image size: {img_size}')\n",
    "        out = critic(z,alpha=0.5, steps=num_steps)\n",
    "\n",
    "        assert out.shape == (1, 1)\n",
    "        print(f'Discriminator Roger Roger at image size: {img_size}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training Loop Hyperparameters\n",
    "START_TRAIN_IMG_SIZE = 4\n",
    "DATASET = 'cryptopunks'\n",
    "CHECKPOINT_GEN = '../runs/ProGAN/checkpoints/generator.pth'\n",
    "CHECKPOINT_DIS = '../runs/ProGAN/checkpoints/discriminator.pth'\n",
    "\n",
    "DEVICE = device = 'mps' if torch.backends.mps.is_available() else 'cpu'\n",
    "SAVE_MODEL = False\n",
    "LOAD_MODEL = False\n",
    "LEARNING_RATE = 3e-4\n",
    "Z_DIM = 512  # should be 512 in original paper\n",
    "IN_CHANNELS = 512  # should be 512 in original paper\n",
    "CRITIC_ITERATIONS = 1\n",
    "BATCH_SIZE = [32, 16, 16, 8, 8, 8, 8, 8, 4]\n",
    "CHANNELS = 3\n",
    "LAMBDA_GP = 10\n",
    "\n",
    "PROGRESSIVE_EPOCHS = [50] * len(BATCH_SIZE)\n",
    "FIXED_NOISE = torch.randn(8, Z_DIM, 1, 1).to(DEVICE)\n",
    "NUM_WORKERS = 4\n",
    "\n",
    "\n",
    "# WEATHER_CONDITIONS = [\n",
    "#     'sunny', 'cloudy', 'rainy', 'snowy', 'windy', 'stormy', 'foggy', 'hail', \n",
    "#     'thunderstorm', 'tornado', 'hurricane', 'blizzard', 'drizzle', 'sleet', \n",
    "#     'dust storm'\n",
    "# ]\n",
    "# COLOURS = [\n",
    "#     'red', 'blue', 'green', 'yellow', 'purple', 'orange', 'black', 'white', \n",
    "#     'pink', 'brown', 'grey', 'violet', 'indigo', 'turquoise', 'gold'\n",
    "# ]\n",
    "\n",
    "# RUN_NAME = f'{WEATHER_CONDITIONS[np.random.randint(0,14)]}-{COLOURS[np.random.randint(0,14)]}'\n",
    "\n",
    "# print(f'Run name: {RUN_NAME}')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter: 50\n",
      "Probability: 0.005\n",
      "Theoretical Probability: 0.0044444444444444444\n"
     ]
    }
   ],
   "source": [
    "counter = 0\n",
    "\n",
    "for i in range(10000):\n",
    "    term = WEATHER_CONDITIONS[np.random.randint(0,14)] + '-' + COLOURS[np.random.randint(0,14)]\n",
    "    if term == RUN_NAME:\n",
    "        counter += 1\n",
    "\n",
    "print(f'Counter: {counter}')\n",
    "print(f'Probability: {counter / 10000}')\n",
    "print(f\"Theoretical Probability: {1/ 15 * 1 /15}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tensorboard\n",
    "writer_fake = SummaryWriter(f'../data/runs/ProGAN/{RUN_NAME}/fake')\n",
    "writer_real = SummaryWriter(f'../data/runs/ProGAN/{RUN_NAME}/real')\n",
    "\n",
    "def plot_to_tensorboard(writer, loss_critic, loss_gen,real,fake, tb_step, run_name):\n",
    "    writer.add_scalar(f'loss_critic', loss_critic, tb_step)\n",
    "    writer.add_scalar(f'loss_gen', loss_gen, tb_step)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        img_grid_fake = torchvision.utils.make_grid(fake[:4], normalize=True)\n",
    "        img_grid_real = torchvision.utils.make_grid(real[:4], normalize=True)\n",
    "\n",
    "        writer.add_image(f'img_grid_fake', img_grid_fake, tb_step)\n",
    "        writer.add_image(f'img_grid_real', img_grid_real, tb_step)\n",
    "\n",
    "def gradient_penalty(critic, real, fake, alpha, train_step, device=\"cpu\"):\n",
    "    BATCH_SIZE, C, H, W = real.shape\n",
    "    beta = torch.rand((BATCH_SIZE, 1, 1, 1)).repeat(1, C, H, W).to(device)\n",
    "    interpolated_images = real * beta + fake.detach() * (1 - beta)\n",
    "    interpolated_images.requires_grad_(True)\n",
    "\n",
    "    # Calculate critic scores\n",
    "    mixed_scores = critic(interpolated_images, alpha, train_step)\n",
    "\n",
    "    # Take the gradient of the scores with respect to the images\n",
    "    gradient = torch.autograd.grad(\n",
    "        inputs=interpolated_images,\n",
    "        outputs=mixed_scores,\n",
    "        grad_outputs=torch.ones_like(mixed_scores),\n",
    "        create_graph=True,\n",
    "        retain_graph=True,\n",
    "    )[0]\n",
    "    gradient = gradient.view(gradient.shape[0], -1)\n",
    "    gradient_norm = gradient.norm(2, dim=1)\n",
    "    gradient_penalty = torch.mean((gradient_norm - 1) ** 2)\n",
    "    return gradient_penalty\n",
    "\n",
    "\n",
    "def save_checkpoint(model, optimizer, filename=\"my_checkpoint.pth.tar\"):\n",
    "    print(\"=> Saving checkpoint\")\n",
    "    checkpoint = {\n",
    "        \"state_dict\": model.state_dict(),\n",
    "        \"optimizer\": optimizer.state_dict(),\n",
    "    }\n",
    "    torch.save(checkpoint, filename)\n",
    "\n",
    "\n",
    "def load_checkpoint(checkpoint_file, model, optimizer, lr):\n",
    "    print(\"=> Loading checkpoint\")\n",
    "    checkpoint = torch.load(checkpoint_file, map_location=\"mps\")\n",
    "    model.load_state_dict(checkpoint[\"state_dict\"])\n",
    "    optimizer.load_state_dict(checkpoint[\"optimizer\"])\n",
    "\n",
    "    # If we don't do this then it will just have learning rate of old checkpoint\n",
    "    # and it will lead to many hours of debugging \\:\n",
    "    for param_group in optimizer.param_groups:\n",
    "        param_group[\"lr\"] = lr\n",
    "\n",
    "def generate_examples(gen, steps, truncation=0.7, n=100):\n",
    "    \"\"\"\n",
    "    Tried using truncation trick here but not sure it actually helped anything, you can\n",
    "    remove it if you like and just sample from torch.randn\n",
    "    \"\"\"\n",
    "    gen.eval()\n",
    "    alpha = 1.0\n",
    "    for i in range(n):\n",
    "        with torch.no_grad():\n",
    "            noise = torch.tensor(truncnorm.rvs(-truncation, truncation, size=(1, Z_DIM, 1, 1)), device=DEVICE, dtype=torch.float32)\n",
    "            img = gen(noise, alpha, steps)\n",
    "            save_image(img*0.5+0.5, f\"saved_examples/img_{i}.png\")\n",
    "    gen.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_loader(image_size):\n",
    "    transform = transforms.Compose([\n",
    "        transforms.Resize((image_size, image_size)),\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Normalize([0.5 for _ in range(CHANNELS)], [0.5 for _ in range(CHANNELS)]),\n",
    "        ])\n",
    "\n",
    "    batch_size = BATCH_SIZE[int(log2(image_size / 4))]\n",
    "\n",
    "    print(batch_size,)\n",
    "    dataset = datasets.ImageFolder(root='../data/cryptopunks/',transform=transform)\n",
    "\n",
    "    loader = DataLoader(dataset, batch_size=batch_size,shuffle=True, num_workers=NUM_WORKERS,pin_memory=True)\n",
    "\n",
    "    return loader, dataset\n",
    "\n",
    "\n",
    "def train(critic,\n",
    "            gen,\n",
    "            loader,\n",
    "            dataset,\n",
    "            step,\n",
    "            alpha,\n",
    "            opt_critic,\n",
    "            opt_gen,\n",
    "            tensorboard_step,\n",
    "            writer\n",
    "            ):\n",
    "    loop = tqdm(loader, leave=True)\n",
    "    for idx, (real, _) in enumerate(loop):\n",
    "        real = real.to(device)\n",
    "        cur_batch_size = real.shape[0]\n",
    "\n",
    "        noise = torch.randn(cur_batch_size, Z_DIM, 1, 1, device=device)\n",
    "\n",
    "        fake = gen(noise, alpha, step)\n",
    "        critic_real = critic(real,alpha,step)\n",
    "        critic_fake = critic(fake.detach(),alpha,step)\n",
    "\n",
    "        gp = gradient_penalty(critic, real, fake,alpha, step,device=DEVICE)\n",
    "\n",
    "        loss_critic = -(torch.mean(critic_real) - torch.mean(critic_fake)) + LAMBDA_GP * gp + (0.001 * torch.mean(critic_real.pow(2)))\n",
    "\n",
    "        opt_critic.zero_grad()\n",
    "        loss_critic.backward()\n",
    "        opt_critic.step()\n",
    "\n",
    "\n",
    "        # Train Generator max E[critic(gen_fake)]\n",
    "        gen_fake = critic(fake, alpha, step)\n",
    "        loss_gen = -torch.mean(gen_fake)\n",
    "\n",
    "        opt_gen.zero_grad()\n",
    "        loss_gen.backward()\n",
    "        opt_gen.step()\n",
    "\n",
    "        alpha  += cur_batch_size / (PROGRESSIVE_EPOCHS[step] * 0.5) * len(dataset) \n",
    "        alpha = min(1, alpha)\n",
    "\n",
    "\n",
    "        if idx % 100 == 0:\n",
    "            with torch.no_grad():\n",
    "                fixed_fakes = gen(FIXED_NOISE, alpha, step) * 0.5 + 0.5\n",
    "\n",
    "            plot_to_tensorboard(writer,\n",
    "                                loss_critic.item(),\n",
    "                                loss_gen.item(),\n",
    "                                real.detach(),\n",
    "                                fixed_fakes.detach(),\n",
    "                                tb_step=tensorboard_step,\n",
    "                                run_name=RUN_NAME)\n",
    "            \n",
    "            tensorboard_step += 1\n",
    "\n",
    "    return tensorboard_step, alpha\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "def main(identifier='',load_gen='', load_cri=''):\n",
    "    gen = Generator(z_dim=Z_DIM, in_channels=IN_CHANNELS, img_channels=CHANNELS).to(DEVICE)\n",
    "    critic = Discriminator(in_channels=IN_CHANNELS, img_channels=CHANNELS).to(DEVICE)\n",
    "\n",
    "    opt_gen = optim.Adam(gen.parameters(), lr=LEARNING_RATE,betas=(0.0,0.99))\n",
    "    opt_critic = optim.Adam(critic.parameters(), lr=LEARNING_RATE,betas=(0.0,0.99))\n",
    "\n",
    "    writer = SummaryWriter(f'../data/runs/ProGAN/{RUN_NAME}/log')\n",
    "\n",
    "    if LOAD_MODEL:\n",
    "        load_checkpoint(\n",
    "            load_gen, gen, opt_gen, LEARNING_RATE,\n",
    "        )\n",
    "        load_checkpoint(\n",
    "            load_cri, critic, opt_critic, LEARNING_RATE,\n",
    "        )\n",
    "\n",
    "\n",
    "    gen.train()\n",
    "    critic.train()\n",
    "\n",
    "\n",
    "    tensorboard_step = 0\n",
    "    step = int(log2(START_TRAIN_IMG_SIZE / 4))\n",
    "\n",
    "    for num_epochs in PROGRESSIVE_EPOCHS[step:]:\n",
    "        alpha = 1e-5 \n",
    "        loader, dataset = get_loader(4 * 2 ** step)\n",
    "        print(f\"Current image size: {4 * 2 ** step}\")\n",
    "\n",
    "        for epoch in range(num_epochs):\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            tensorboard_step, alpha = train(\n",
    "                critic,\n",
    "                gen,\n",
    "                loader,\n",
    "                dataset,\n",
    "                step,\n",
    "                alpha,\n",
    "                opt_critic,\n",
    "                opt_gen,\n",
    "                tensorboard_step,\n",
    "                writer\n",
    "            )\n",
    "\n",
    "            if SAVE_MODEL:\n",
    "                save_checkpoint(gen, opt_gen, filename=CHECKPOINT_GEN + f'step {step} epoch {epoch}')\n",
    "                save_checkpoint(critic, opt_critic, filename=CHECKPOINT_DIS + f'step {step} epoch {epoch}')\n",
    "\n",
    "        step += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "32\n",
      "Current image size: 4\n",
      "Epoch [1/35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:34<00:00,  9.04it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [2/35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:33<00:00,  9.25it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [3/35]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 313/313 [00:18<00:00, 16.87it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m main(load_gen\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m,load_cri\u001b[39m=\u001b[39;49m\u001b[39m'\u001b[39;49m\u001b[39m'\u001b[39;49m)\n",
      "\u001b[1;32m/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=109'>110</a>\u001b[0m \u001b[39mfor\u001b[39;00m epoch \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(num_epochs):\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=110'>111</a>\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mEpoch [\u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m/\u001b[39m\u001b[39m{\u001b[39;00mnum_epochs\u001b[39m}\u001b[39;00m\u001b[39m]\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m--> <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=111'>112</a>\u001b[0m     tensorboard_step, alpha \u001b[39m=\u001b[39m train(\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=112'>113</a>\u001b[0m         critic,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=113'>114</a>\u001b[0m         gen,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=114'>115</a>\u001b[0m         loader,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=115'>116</a>\u001b[0m         dataset,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=116'>117</a>\u001b[0m         step,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=117'>118</a>\u001b[0m         alpha,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=118'>119</a>\u001b[0m         opt_critic,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=119'>120</a>\u001b[0m         opt_gen,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=120'>121</a>\u001b[0m         tensorboard_step,\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=121'>122</a>\u001b[0m         writer\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=122'>123</a>\u001b[0m     )\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=124'>125</a>\u001b[0m     \u001b[39mif\u001b[39;00m SAVE_MODEL:\n\u001b[1;32m    <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=125'>126</a>\u001b[0m         save_checkpoint(gen, opt_gen, filename\u001b[39m=\u001b[39mCHECKPOINT_GEN \u001b[39m+\u001b[39m \u001b[39mf\u001b[39m\u001b[39m'\u001b[39m\u001b[39mstep \u001b[39m\u001b[39m{\u001b[39;00mstep\u001b[39m}\u001b[39;00m\u001b[39m epoch \u001b[39m\u001b[39m{\u001b[39;00mepoch\u001b[39m}\u001b[39;00m\u001b[39m'\u001b[39m)\n",
      "\u001b[1;32m/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb Cell 11\u001b[0m line \u001b[0;36m3\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mtrain\u001b[39m(critic,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m             gen,\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m             loader,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=26'>27</a>\u001b[0m             writer\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=27'>28</a>\u001b[0m             ):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=28'>29</a>\u001b[0m     loop \u001b[39m=\u001b[39m tqdm(loader, leave\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[0;32m---> <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=29'>30</a>\u001b[0m     \u001b[39mfor\u001b[39;00m idx, (real, _) \u001b[39min\u001b[39;00m \u001b[39menumerate\u001b[39m(loop):\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=30'>31</a>\u001b[0m         real \u001b[39m=\u001b[39m real\u001b[39m.\u001b[39mto(device)\n\u001b[1;32m     <a href='vscode-notebook-cell:/Users/luca/Desktop/Projects/ML/CryptopunkVAE/notebooks/ProGAN.ipynb#X13sZmlsZQ%3D%3D?line=31'>32</a>\u001b[0m         cur_batch_size \u001b[39m=\u001b[39m real\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/site-packages/tqdm/std.py:1182\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1179\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[1;32m   1181\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m-> 1182\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[1;32m   1183\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[1;32m   1184\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[1;32m   1185\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/site-packages/torch/utils/data/dataloader.py:630\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    627\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    628\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[1;32m    629\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[0;32m--> 630\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[1;32m    631\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[1;32m    632\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    633\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[1;32m    634\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1317\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._next_data\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1314\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m   1315\u001b[0m     \u001b[39m# no valid `self._rcvd_idx` is found (i.e., didn't break)\u001b[39;00m\n\u001b[1;32m   1316\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_persistent_workers:\n\u001b[0;32m-> 1317\u001b[0m         \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_shutdown_workers()\n\u001b[1;32m   1318\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m\n\u001b[1;32m   1320\u001b[0m \u001b[39m# Now `self._rcvd_idx` is the batch index we want to fetch\u001b[39;00m\n\u001b[1;32m   1321\u001b[0m \n\u001b[1;32m   1322\u001b[0m \u001b[39m# Check if the next sample has already been generated\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/site-packages/torch/utils/data/dataloader.py:1442\u001b[0m, in \u001b[0;36m_MultiProcessingDataLoaderIter._shutdown_workers\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1437\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_mark_worker_as_unavailable(worker_id, shutdown\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m)\n\u001b[1;32m   1438\u001b[0m \u001b[39mfor\u001b[39;00m w \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_workers:\n\u001b[1;32m   1439\u001b[0m     \u001b[39m# We should be able to join here, but in case anything went\u001b[39;00m\n\u001b[1;32m   1440\u001b[0m     \u001b[39m# wrong, we set a timeout and if the workers fail to join,\u001b[39;00m\n\u001b[1;32m   1441\u001b[0m     \u001b[39m# they are killed in the `finally` block.\u001b[39;00m\n\u001b[0;32m-> 1442\u001b[0m     w\u001b[39m.\u001b[39;49mjoin(timeout\u001b[39m=\u001b[39;49m_utils\u001b[39m.\u001b[39;49mMP_STATUS_CHECK_INTERVAL)\n\u001b[1;32m   1443\u001b[0m \u001b[39mfor\u001b[39;00m q \u001b[39min\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_index_queues:\n\u001b[1;32m   1444\u001b[0m     q\u001b[39m.\u001b[39mcancel_join_thread()\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/multiprocessing/process.py:149\u001b[0m, in \u001b[0;36mBaseProcess.join\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    147\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_parent_pid \u001b[39m==\u001b[39m os\u001b[39m.\u001b[39mgetpid(), \u001b[39m'\u001b[39m\u001b[39mcan only join a child process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[39massert\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_popen \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m, \u001b[39m'\u001b[39m\u001b[39mcan only join a started process\u001b[39m\u001b[39m'\u001b[39m\n\u001b[0;32m--> 149\u001b[0m res \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_popen\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[1;32m    150\u001b[0m \u001b[39mif\u001b[39;00m res \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m    151\u001b[0m     _children\u001b[39m.\u001b[39mdiscard(\u001b[39mself\u001b[39m)\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/multiprocessing/popen_fork.py:40\u001b[0m, in \u001b[0;36mPopen.wait\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m     38\u001b[0m \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m     39\u001b[0m     \u001b[39mfrom\u001b[39;00m \u001b[39mmultiprocessing\u001b[39;00m\u001b[39m.\u001b[39;00m\u001b[39mconnection\u001b[39;00m \u001b[39mimport\u001b[39;00m wait\n\u001b[0;32m---> 40\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m wait([\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49msentinel], timeout):\n\u001b[1;32m     41\u001b[0m         \u001b[39mreturn\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     42\u001b[0m \u001b[39m# This shouldn't block if wait() returned successfully.\u001b[39;00m\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/multiprocessing/connection.py:931\u001b[0m, in \u001b[0;36mwait\u001b[0;34m(object_list, timeout)\u001b[0m\n\u001b[1;32m    928\u001b[0m     deadline \u001b[39m=\u001b[39m time\u001b[39m.\u001b[39mmonotonic() \u001b[39m+\u001b[39m timeout\n\u001b[1;32m    930\u001b[0m \u001b[39mwhile\u001b[39;00m \u001b[39mTrue\u001b[39;00m:\n\u001b[0;32m--> 931\u001b[0m     ready \u001b[39m=\u001b[39m selector\u001b[39m.\u001b[39;49mselect(timeout)\n\u001b[1;32m    932\u001b[0m     \u001b[39mif\u001b[39;00m ready:\n\u001b[1;32m    933\u001b[0m         \u001b[39mreturn\u001b[39;00m [key\u001b[39m.\u001b[39mfileobj \u001b[39mfor\u001b[39;00m (key, events) \u001b[39min\u001b[39;00m ready]\n",
      "File \u001b[0;32m~/miniconda3/envs/vae/lib/python3.10/selectors.py:416\u001b[0m, in \u001b[0;36m_PollLikeSelector.select\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    414\u001b[0m ready \u001b[39m=\u001b[39m []\n\u001b[1;32m    415\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m--> 416\u001b[0m     fd_event_list \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_selector\u001b[39m.\u001b[39;49mpoll(timeout)\n\u001b[1;32m    417\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mInterruptedError\u001b[39;00m:\n\u001b[1;32m    418\u001b[0m     \u001b[39mreturn\u001b[39;00m ready\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "main(load_gen='',load_cri='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
